// Test script to check if we can use a different model\nconst fs = require('fs');\nconst path = require('path');\n\n// Read the environment variables\nrequire('dotenv').config({ path: path.resolve(__dirname, '.env.local') });\n\nconsole.log('=== TESTING ALTERNATIVE MODELS ===');\n\n// Test with a different model that might not be rate limited\nasync function testAlternativeModel() {\n  const alternativeModels = [\n    'mistralai/mistral-7b-instruct:free',\n    'google/gemma-7b-it:free',\n    'meta-llama/llama-3-8b-instruct:free'\n  ];\n  \n  for (const model of alternativeModels) {\n    console.log(`\\nTesting model: ${model}`);\n    \n    try {\n      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,\n          'Content-Type': 'application/json',\n          'HTTP-Referer': 'https://kims-dating-coach.com',\n        },\n        body: JSON.stringify({\n          model: model,\n          messages: [\n            {\n              role: 'user',\n              content: 'Just respond with \"SUCCESS\" to confirm the API is working'\n            }\n          ],\n          temperature: 0.7,\n          max_tokens: 10\n        })\n      });\n      \n      console.log(`  Status: ${response.status}`);\n      \n      if (response.ok) {\n        const data = await response.json();\n        console.log(`  Response: ${data.choices[0].message.content}`);\n        console.log(`  ✅ ${model} is available`);\n        return model; // Return the first working model\n      } else {\n        const errorData = await response.json();\n        console.log(`  ❌ Error: ${JSON.stringify(errorData.error || errorData)`);\n      }\n    } catch (error) {\n      console.log(`  ❌ Failed: ${error.message}`);\n    }\n  }\n  \n  console.log('\\nNo alternative models are currently available');\n  return null;\n}\n\n// Run the test\ntestAlternativeModel().catch(console.error);